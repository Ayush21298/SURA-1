{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pysrt\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "from inference_util import Inference\n",
    "from model import Model_S2VT\n",
    "import configuration\n",
    "import inception_base\n",
    "\n",
    "from data_generator import Data_Generator\n",
    "\n",
    "video_path = \"/home/ozym4nd145/Downloads/[9anime.to] Boku no Hero Academia 2nd Season - 09 - 720p.mp4\"\n",
    "\n",
    "srt_path = os.path.splitext(video_path)[0]+\".srt\"\n",
    "\n",
    "checkpoint_path = \"../../dataset/inception_v4.ckpt\"\n",
    "\n",
    "num_frames_per_sec=10\n",
    "num_frames_per_clip = 100\n",
    "\n",
    "max_len=20\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "time_length = length/fps\n",
    "\n",
    "num_frames_to_read = int((int(time_length)*(num_frames_per_sec))/num_frames_per_clip)*num_frames_per_clip\n",
    "\n",
    "frames_to_read = set(np.linspace(0,length-1,num=num_frames_to_read,dtype=np.int32))\n",
    "\n",
    "## Building model\n",
    "image_feed = tf.placeholder(dtype=tf.float32,shape=[None,299,299,3],name=\"image_feed\")\n",
    "inception_output = inception_base.get_base_model(image_feed)\n",
    "inception_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"InceptionV4\")\n",
    "\n",
    "data_config = configuration.DataConfig().config\n",
    "data_gen = Data_Generator(processed_video_dir = data_config[\"processed_video_dir\"],\n",
    "                         caption_file = data_config[\"caption_file\"],\n",
    "                         unique_freq_cutoff = data_config[\"unique_frequency_cutoff\"],\n",
    "                         max_caption_len = data_config[\"max_caption_length\"])\n",
    "\n",
    "data_gen.load_vocabulary(data_config[\"caption_data_dir\"])\n",
    "data_gen.load_dataset(data_config[\"caption_data_dir\"])\n",
    "\n",
    "model_config = configuration.ModelConfig(data_gen).config\n",
    "model = Model_S2VT( num_frames = model_config[\"num_frames\"],\n",
    "                    image_width = model_config[\"image_width\"],\n",
    "                    image_height = model_config[\"image_height\"],\n",
    "                    image_channels = model_config[\"image_channels\"],\n",
    "                    num_caption_unroll = model_config[\"num_caption_unroll\"],\n",
    "                    num_last_layer_units = model_config[\"num_last_layer_units\"],\n",
    "                    image_embedding_size = model_config[\"image_embedding_size\"],\n",
    "                    word_embedding_size = model_config[\"word_embedding_size\"],\n",
    "                    hidden_size_lstm1 = model_config[\"hidden_size_lstm1\"],\n",
    "                    hidden_size_lstm2 = model_config[\"hidden_size_lstm2\"],\n",
    "                    vocab_size = model_config[\"vocab_size\"],\n",
    "                    initializer_scale = model_config[\"initializer_scale\"],\n",
    "                    learning_rate = model_config[\"learning_rate\"],\n",
    "                    mode=\"inference\",\n",
    "                    rnn1_input_keep_prob=model_config[\"rnn1_input_keep_prob\"],\n",
    "                    rnn1_output_keep_prob=model_config[\"rnn1_output_keep_prob\"],\n",
    "                    rnn2_input_keep_prob=model_config[\"rnn2_input_keep_prob\"],\n",
    "                    rnn2_output_keep_prob=model_config[\"rnn2_output_keep_prob\"]\n",
    "                    )\n",
    "model.build()\n",
    "\n",
    "infer_util = Inference(model,data_gen.word_to_idx,data_gen.idx_to_word)\n",
    "\n",
    "tf.trainable_variables()\n",
    "\n",
    "tf.contrib.framework.list_variables(\"../E5/models/train/model-10144\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.Saver(var_list=inception_variables)\n",
    "saver.restore(sess,checkpoint_path)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "saver.restore(sess,\"../E5/models/train/model-10680\")\n",
    "\n",
    "captions=[]\n",
    "\n",
    "frame_list = []\n",
    "\n",
    "num_frames_per_clip*batch_size\n",
    "\n",
    "start_time=0\n",
    "\n",
    "processed_batch=[]\n",
    "\n",
    "frame_list= []\n",
    "for i in range(length):\n",
    "    ret, frame = video.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "    if i in frames_to_read:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = misc.imresize(frame,[299,299,3])\n",
    "        frame = ((2*(frame.astype(np.float32) / 255 ))-1)\n",
    "        frame = sess.run(inception_output,feed_dict={image_feed:[frame]})\n",
    "        frame_list.append(frame)\n",
    "        if len(frame_list)%100==0:\n",
    "            print(len(frame_list))\n",
    "    if len(frame_list)==(num_frames_per_clip*batch_size):\n",
    "        print(\"Processing batch\")\n",
    "        processed_batch = np.array(frame_list,dtype=np.float32)\n",
    "        embedded_frames = np.reshape(processed_batch,[-1,num_frames_per_clip,inception_base.num_end_units_v4])\n",
    "        caption_batch = infer_util.generate_caption_batch(sess,embedded_frames,max_len=max_len)\n",
    "        for cap in caption_batch:\n",
    "            caption = {}\n",
    "            caption[\"start_time\"] = start_time\n",
    "            caption[\"end_time\"] = start_time+ (num_frames_per_clip/num_frames_per_sec)\n",
    "            start_time = caption[\"end_time\"]\n",
    "            caption[\"caption\"] = cap\n",
    "            captions.append(caption)\n",
    "        frame_list = []\n",
    "        del processed_batch\n",
    "        del embedded_frames\n",
    "        del caption_batch\n",
    "\n",
    "subtitles = pysrt.srtfile.SubRipFile()\n",
    "\n",
    "index = 1\n",
    "\n",
    "for caption in captions:\n",
    "    sub = pysrt.srtitem.SubRipItem()\n",
    "    sub.start.seconds = caption[\"start_time\"]\n",
    "    sub.end.seconds = caption[\"end_time\"]\n",
    "    sub.text = caption[\"caption\"]\n",
    "    sub.index = index\n",
    "    index += 1\n",
    "    subtitles.append(sub)\n",
    "\n",
    "subtitles.save(srt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
