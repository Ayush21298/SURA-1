{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "from model import Caption_Model\n",
    "from data_generator import Data_Generator\n",
    "from inference_util import Inference\n",
    "\n",
    "import inception_base\n",
    "import configuration\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64,\n",
    "                       \"Batch size of train data input.\")\n",
    "tf.flags.DEFINE_integer(\"beam_size\", 3,\n",
    "                       \"Beam size.\")\n",
    "tf.flags.DEFINE_string(\"checkpoint_model\", None,\n",
    "                       \"Model Checkpoint to use.\")\n",
    "tf.flags.DEFINE_integer(\"max_captions\", None,\n",
    "                       \"Maximum number of captions to generate\")\n",
    "tf.flags.DEFINE_integer(\"max_len_captions\", None,\n",
    "                       \"Maximum length of captions to generate\")\n",
    "tf.flags.DEFINE_string(\"dataset\", \"test\",\n",
    "                       \"Dataset to use\")\n",
    "tf.flags.DEFINE_string(\"outfile_name\", \"generated_caption.json\",\n",
    "                       \"Name of the output result file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_config = configuration.DataConfig().config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = tf.train.latest_checkpoint(data_config[\"checkpoint_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_paths=[model_path]\n",
    "dataset=\"test\"\n",
    "batch_size=64\n",
    "max_len_captions=20\n",
    "max_captions=None\n",
    "beam_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_config = configuration.DataConfig().config\n",
    "data_gen = Data_Generator(processed_video_dir = data_config[\"processed_video_dir\"],\n",
    "                        caption_file = data_config[\"caption_file\"],\n",
    "                        unique_freq_cutoff = data_config[\"unique_frequency_cutoff\"],\n",
    "                        max_caption_len = data_config[\"max_caption_length\"])\n",
    "\n",
    "data_gen.load_vocabulary(data_config[\"caption_data_dir\"])\n",
    "data_gen.load_dataset(data_config[\"caption_data_dir\"])\n",
    "\n",
    "assert dataset in [\"val\",\"test\",\"train\"]\n",
    "\n",
    "if max_len_captions:\n",
    "    max_len = max_len_captions\n",
    "else:\n",
    "    max_len = data_config['max_caption_length']\n",
    "\n",
    "model_config = configuration.ModelConfig(data_gen).config\n",
    "model = Caption_Model( **model_config,mode=\"inference\")\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infer_util = Inference(model,data_gen.word_to_idx,data_gen.idx_to_word)\n",
    "\n",
    "if max_captions:\n",
    "    max_iter = max_captions\n",
    "else:\n",
    "    max_iter = len(data_gen.dataset[dataset])+10 #+10 is just to be safe ;)\n",
    "\n",
    "video_paths = {i[\"file_name\"]:i[\"path\"] for i in data_gen.dataset[dataset]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_captions = []\n",
    "sess = tf.Session()\n",
    "model_path = model_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_caption = []    \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if model_path != None:\n",
    "    print(\"Restoring weights from %s\" %model_path)\n",
    "    saver.restore(sess,model_path)\n",
    "\n",
    "else:\n",
    "    print(\"No checkpoint found. Exiting\")\n",
    "\n",
    "video_files = list(video_paths.keys())    \n",
    "\n",
    "iter = 0\n",
    "btch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = btch\n",
    "end = min(len(video_files),btch+batch_size)\n",
    "dataset={}\n",
    "dataset[\"video\"] = np.asarray([np.load(video_paths[video_files[i]]) for i in range(start,end)])\n",
    "dataset[\"path\"] = [video_paths[video_files[i]] for i in range(start,end)]\n",
    "dataset[\"file\"] = [video_files[i] for i in range(start,end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[\"gen_caption\"] = infer_util.generate_caption_batch_beam(sess,dataset[\"video\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(dataset['gen_caption'])):\n",
    "    dictionary = {}\n",
    "    dictionary[\"gen_caption\"] = dataset['gen_caption'][i]\n",
    "    dictionary[\"file_name\"] = dataset['file'][i]\n",
    "    dictionary[\"path\"] = dataset['path'][i]\n",
    "    gen_caption.append(dictionary)\n",
    "    iter+=1\n",
    "    if iter >= max_iter:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
