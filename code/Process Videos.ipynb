{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import tensorflow as tf\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import inception_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initialize Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_val_video_path = \"..\\\\SURA\\\\dataset\\\\raw\\\\MSR-VTT_2016\\\\TrainValVideo\\\\\"\n",
    "test_video_path = \"..\\\\SURA\\\\dataset\\\\raw\\\\MSR-VTT_2016\\\\TestVideo/\"\n",
    "base_save_path = \".\\\\\"\n",
    "num_frames_per_video = 100\n",
    "vid_filter = lambda x: x.endswith('mp4')\n",
    "train_filter =  lambda x: 0 <= int(x[5:][:-4]) <= 6512\n",
    "val_filter =  lambda x: 6513 <= int(x[5:][:-4]) <= 7009\n",
    "test_filter =  lambda x: 7010 <= int(x[5:][:-4]) <= 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "videos = os.listdir(train_val_video_path) +  os.listdir(test_video_path)\n",
    "videos = list(filter(vid_filter,videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Inception Model Declare and restore Weights``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Inception_Model(object):\n",
    "    def __init__(self,learning_rate=1e-3,initializer_scale=0.5):     \n",
    "        self.learning_rate = learning_rate\n",
    "        self.initializer = tf.random_uniform_initializer(\n",
    "                                            minval=-initializer_scale,\n",
    "                                            maxval=initializer_scale)\n",
    "        self.images = None\n",
    "        # Global step Tensor.\n",
    "        self.global_step = None\n",
    "    def build_inputs_outputs(self):\n",
    "        self.image_feed = tf.placeholder(dtype=tf.float32,shape=[None,299,299,3],name=\"image_feed\")        \n",
    "    def build_image_embedding(self):\n",
    "        self.inception_output = inception_base.get_base_model(self.image_feed)\n",
    "        self.fine_tune_input = tf.placeholder_with_default(self.inception_output,self.inception_output.get_shape(),name=\"fine_tune_input\")\n",
    "        self.inception_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"InceptionV4\")\n",
    "#     def setup_global_step(self):\n",
    "#         \"\"\"Sets up the global step Tensor.\"\"\"\n",
    "#         global_step = tf.Variable(\n",
    "#             initial_value=0,\n",
    "#             name=\"global_step\",\n",
    "#             trainable=False,\n",
    "#             collections=[tf.GraphKeys.GLOBAL_STEP, tf.GraphKeys.GLOBAL_VARIABLES])\n",
    "#         self.global_step = global_step\n",
    "        \n",
    "    def build(self):\n",
    "        self.build_inputs_outputs()\n",
    "        self.build_image_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Inception_Model()\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./inception_v4.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=model.inception_variables)\n",
    "saver.restore(sess,\"./inception_v4.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#out = sess.run(model.inception_output,feed_dict={model.image_feed:IMAGE_BATCH_ARRAY)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main Function to read video, trim frames, and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    #p = os.path.join(train_val_video_path+x)\n",
    "    cap  = cv2.VideoCapture( video_path )\n",
    "    frame_count = 0\n",
    "    frame_list = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "        frame_list.append(frame)\n",
    "        frame_count += 1\n",
    "    frame_list = np.array(frame_list)\n",
    "    if frame_count > num_frames_per_video:\n",
    "            frame_indices = np.linspace(0, frame_count-1, num=num_frames_per_video, endpoint=True).astype(int)\n",
    "            frame_list = frame_list[frame_indices]\n",
    "    frame_list = [cv2.cvtColor(x, cv2.COLOR_BGR2RGB) for x in frame_list]\n",
    "    frame_list_resized = [scipy.misc.imresize(frame,[299,299,3]) for frame in frame_list]\n",
    "    frame_list_processed = [((2*(frame.astype(np.float32) / 255 ))-1) for frame in frame_list_resized]\n",
    "    frame_list = np.array(frame_list_processed)\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.6,  1.2,  1.8,  2.4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0,3,5,endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([5],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z=  [1]*5+[0]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(z,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "z[0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cap  = cv2.VideoCapture(\"/home/ozym4nd145/Coding/Notebook/SURA/dataset/raw/MSR-VTT_2016/TrainValVideo/video1648.mp4\")\n",
    "cap  = cv2.VideoCapture(\"../dataset/raw/MSR-VTT_2016/TrainValVideo/video16.mp4\")\n",
    "frame_count = 0\n",
    "frame_list = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "    frame_list.append(frame)\n",
    "    frame_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv2.VideoCapture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train, Val and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos, currently at video1087.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1177.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1267.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1357.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1447.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1537.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1627.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1717.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1807.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1898.mp4\n",
      "\n",
      "Processed 100 videos, currently at video1988.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2077.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2167.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2257.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2347.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2437.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2527.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2617.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2707.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2798.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2888.mp4\n",
      "\n",
      "Processed 100 videos, currently at video2978.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3067.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3157.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3247.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3337.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3427.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3517.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3607.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3698.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3788.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3878.mp4\n",
      "\n",
      "Processed 100 videos, currently at video3968.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4057.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4147.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4237.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4327.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4417.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4507.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4598.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4688.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4778.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4868.mp4\n",
      "\n",
      "Processed 100 videos, currently at video4958.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5047.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5137.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5227.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5317.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5407.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5498.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5588.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5678.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5768.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5858.mp4\n",
      "\n",
      "Processed 100 videos, currently at video5948.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6037.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6127.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6217.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6307.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6398.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6488.mp4\n",
      "\n",
      "Processed 100 videos, currently at video716.mp4\n",
      "\n",
      "Processed 100 videos, currently at video806.mp4\n",
      "\n",
      "Processed 100 videos, currently at video897.mp4\n",
      "\n",
      "Processed 100 videos, currently at video987.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for vid in  filter(train_filter,videos):\n",
    "    read_path = os.path.join(train_val_video_path,vid)\n",
    "    save_path = os.path.join(base_save_path,\"train\",vid+\".npy\")\n",
    "    if(not os.path.exists(save_path)):\n",
    "        preprocessed_frames = read_video(read_path)\n",
    "        completed_frames = sess.run(model.inception_output,feed_dict={model.image_feed:preprocessed_frames})\n",
    "        np.save(save_path,completed_frames)\n",
    "        if count%100 == 0:\n",
    "            print(\"Processed 100 videos, currently at \"+vid+\"\\n\")\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos, currently at video7109.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7209.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7309.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7409.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7509.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7609.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7709.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7809.mp4\n",
      "\n",
      "Processed 100 videos, currently at video7909.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8009.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8109.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8209.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8309.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8409.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8509.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8609.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8709.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8809.mp4\n",
      "\n",
      "Processed 100 videos, currently at video8909.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9009.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9109.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9209.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9309.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9409.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9509.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9609.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9709.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9809.mp4\n",
      "\n",
      "Processed 100 videos, currently at video9909.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for vid in  filter(test_filter,videos):\n",
    "    read_path = os.path.join(test_video_path,vid)\n",
    "    save_path = os.path.join(base_save_path,\"test\",vid+\".npy\")\n",
    "    if(not os.path.exists(save_path)):\n",
    "        preprocessed_frames = read_video(read_path)\n",
    "        completed_frames = sess.run(model.inception_output,feed_dict={model.image_feed:preprocessed_frames})\n",
    "        np.save(save_path,completed_frames)\n",
    "        if count%100 == 0:\n",
    "            print(\"Processed 100 videos, currently at \"+vid+\"\\n\")\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 videos, currently at video6612.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6712.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6812.mp4\n",
      "\n",
      "Processed 100 videos, currently at video6912.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for vid in  filter(val_filter,videos):\n",
    "    read_path = os.path.join(train_val_video_path,vid)\n",
    "    save_path = os.path.join(base_save_path,\"val\",vid+\".npy\")\n",
    "    if(not os.path.exists(save_path)):\n",
    "        preprocessed_frames = read_video(read_path)\n",
    "        completed_frames = sess.run(model.inception_output,feed_dict={model.image_feed:preprocessed_frames})\n",
    "        np.save(save_path,completed_frames)\n",
    "        if count%100 == 0:\n",
    "            print(\"Processed 100 videos, currently at \"+vid+\"\\n\")\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preprocessed_frames = read_video(read_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preprocessed_frames[8][77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cv2 gives height, width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',frame_list[0])\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(preprocessed_frames[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "frame_list = np.array(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if frame_count > num_frames_per_video:\n",
    "            frame_indices = np.linspace(0, frame_count-1, num=num_frames_per_video, endpoint=True).astype(int)\n",
    "            frame_list = frame_list[frame_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "frame_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = scipy.ndimage.imread(\"12447.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = scipy.misc.imresize(d,[300,300,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import configuration\n",
    "from data_generator import Data_Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_config = configuration.DataConfig().config\n",
    "data_gen = Data_Generator(data_config[\"processed_video_dir\"],\n",
    "                        data_config[\"caption_file\"],\n",
    "                        data_config[\"unique_frequency_cutoff\"],\n",
    "                        data_config[\"max_caption_length\"])\n",
    "\n",
    "data_gen.load_vocabulary(data_config[\"caption_data_dir\"])\n",
    "data_gen.load_dataset(data_config[\"caption_data_dir\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref = {'info':{},'images':[],'licenses':[],'type':'captions','annotations':[]}\n",
    "\n",
    "ref['info'] = {'contributor': 'Suyash Agrawal',\n",
    "               'date_created': '2017-06-08',\n",
    "               'description': 'test',\n",
    "               'url': 'https://github.com/ozym4nd145',\n",
    "               'version': '1.0',\n",
    "               'year': 2017}\n",
    "\n",
    "ref['licenses'].append({'id': 1,\n",
    "                        'name': 'Attribution-NonCommercial-ShareAlike License',\n",
    "                        'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/'})\n",
    "\n",
    "video_to_id = {}\n",
    "id_to_video = {}\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for i in data_gen.dataset.keys():\n",
    "    all_data += data_gen.dataset[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caption': 'a woman is adding and stirring in three different ingredients into a bowl of cooked white rice',\n",
       " 'caption_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], dtype=int32),\n",
       " 'file_name': '0lh_UWF9ZP4_50_60.avi.npy',\n",
       " 'indexed_caption': array([  1,   4,   8,   5, 204,  13, 221,   9, 121, 719, 233,  18,   4,\n",
       "         57,  14, 371, 144, 130,   2,   0,   0], dtype=int32),\n",
       " 'path': '../dataset/MSVD_processed/val/0lh_UWF9ZP4_50_60.avi.npy',\n",
       " 'processed_caption': '<bos> a woman is adding and stirring in three different ingredients into a bowl of cooked white rice <eos> <pad> <pad>',\n",
       " 'real_caption': 'a woman is adding and stirring in three different ingredients into a bowl of cooked white rice.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "video_ids = list(set([i['file_name'][:-4] for i in all_data]))\n",
    "\n",
    "video_ids.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx,name in enumerate(video_ids):\n",
    "    dictionary = {}\n",
    "    dictionary['file_name'] = name[:-4]\n",
    "    dictionary['id'] = idx\n",
    "    dictionary['license'] = 1\n",
    "    ref['images'].append(dictionary)\n",
    "    video_to_id[name[:-4]] = idx\n",
    "    id_to_video[idx] = name[:-4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.sort(key= lambda x: (x[\"file_name\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
